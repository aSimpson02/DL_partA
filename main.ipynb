{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels...\n",
      "Loaded 2016 labels.\n",
      "Loading Images...\n",
      "Loaded 2016 images.\n",
      "Parsing Labels...\n"
     ]
    }
   ],
   "source": [
    "#paths...\n",
    "BASE = \"Database\"\n",
    "IMAGES_PATH = os.path.join(BASE, \"Image\")\n",
    "LABELS_PATH = os.path.join(BASE, \"label.txt\")\n",
    "\n",
    "\n",
    "#labels...\n",
    "def load_labels(labels_path):\n",
    "    with open(labels_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()  \n",
    "        if len(parts) >= 3:  \n",
    "            try:\n",
    "                pose = float(parts[1]) \n",
    "                depth = float(parts[2])  \n",
    "                labels.append([pose, depth])  \n",
    "            except ValueError:\n",
    "                print(f\"Skipping line due to ValueError: {line}\")  \n",
    "        else:\n",
    "            print(f\"Skipping line due to incorrect format: {line}\") \n",
    "    print(f\"Loaded {len(labels)} labels.\") \n",
    "    return labels\n",
    "\n",
    "\n",
    "#images...\n",
    "def load_images(images_path):\n",
    "    image_paths = []\n",
    "    images = []\n",
    "    for filename in os.listdir(images_path):\n",
    "        if filename.endswith(\".jpeg\") or filename.endswith(\".jpg\"):  \n",
    "            image_paths.append(os.path.join(images_path, filename))\n",
    "            img = cv2.imread(os.path.join(images_path, filename))\n",
    "            if img is not None:\n",
    "                images.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  \n",
    "    print(f\"Loaded {len(images)} images.\")  \n",
    "    return np.array(images), image_paths\n",
    "\n",
    "\n",
    "#data vis\n",
    "def plot_label_distribution(labels_df):\n",
    "    if labels_df.empty:\n",
    "        print(\"No data available for plotting.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(labels_df[\"Pitch\"], bins=20, alpha=0.7, label=\"Pitch\")\n",
    "    plt.hist(labels_df[\"Roll\"], bins=20, alpha=0.7, label=\"Roll\")\n",
    "    plt.hist(labels_df[\"Depth\"], bins=20, alpha=0.7, label=\"Depth\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Label Distributions\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_samples(images, labels_df, sample_size=5):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sample_indices = np.random.choice(len(images), size=sample_size, replace=False)\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        plt.subplot(1, sample_size, i+1)\n",
    "        plt.imshow(images[idx])\n",
    "        plt.title(f\"Image {labels_df.iloc[idx]['Image']}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "print(\"Loading Labels...\")\n",
    "labels = load_labels(LABELS_PATH)\n",
    "\n",
    "print(\"Loading Images...\")\n",
    "images, image_paths = load_images(IMAGES_PATH)\n",
    "\n",
    "\n",
    "if images.size == 0 or not labels:\n",
    "    raise ValueError(\"No data loaded. Ensure the dataset paths are correct.\")\n",
    "\n",
    "#parsing labels...\n",
    "print(\"Parsing Labels...\")\n",
    "labels = np.array(labels, dtype=np.float32)\n",
    "y_pose = labels[:, 0]  \n",
    "depth_labels = labels[:, 1]  \n",
    "\n",
    "#normalise\n",
    "X_images = images / 255.0\n",
    "\n",
    "\n",
    "y_labels_combined = np.stack((y_pose, depth_labels), axis=1)\n",
    "\n",
    "#splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_images, y_labels_combined, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (0,)\n",
      "Labels shape: (0, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation...\n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN classification...\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "def build_cnn(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "cnn_model = build_cnn((224, 224, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint\n\u001b[1;32m      4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_best_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m history_cnn \u001b[38;5;241m=\u001b[39m cnn_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m----> 7\u001b[0m     augmenter\u001b[38;5;241m.\u001b[39mflow(\u001b[43mX_train\u001b[49m, y_train[:, :\u001b[38;5;241m2\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m),\n\u001b[1;32m      8\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val[:, :\u001b[38;5;241m2\u001b[39m]),\n\u001b[1;32m      9\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m     10\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint]\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#training....\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('cnn_best_model.keras', save_best_only=True, monitor='val_accuracy')\n",
    "\n",
    "history_cnn = cnn_model.fit(\n",
    "    augmenter.flow(X_train, y_train[:, :2], batch_size=128),\n",
    "    validation_data=(X_val, y_val[:, :2]),\n",
    "    epochs=25,\n",
    "    callbacks=[checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training visualisation...\n",
    "def plot_training(history):\n",
    "    if history is None:\n",
    "        print(\"No training history available to plot.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression model...\n",
    "def build_regression_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "regression_model = build_regression_model((224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#training regression...\u001b[39;00m\n\u001b[1;32m      2\u001b[0m checkpoint_regression \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression_best_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m history_regression \u001b[38;5;241m=\u001b[39m regression_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m----> 5\u001b[0m     augmenter\u001b[38;5;241m.\u001b[39mflow(\u001b[43mX_train\u001b[49m, y_train[:, \u001b[38;5;241m2\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m),\n\u001b[1;32m      6\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val[:, \u001b[38;5;241m2\u001b[39m]),\n\u001b[1;32m      7\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m      8\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint_regression]\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#training regression...\n",
    "checkpoint_regression = ModelCheckpoint('regression_best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "history_regression = regression_model.fit(\n",
    "    augmenter.flow(X_train, y_train[:, 2], batch_size=128),\n",
    "    validation_data=(X_val, y_val[:, 2]),\n",
    "    epochs=25,\n",
    "    callbacks=[checkpoint_regression]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_regression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 18\u001b[0m plot_regression_results(\u001b[43mhistory_regression\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_regression' is not defined"
     ]
    }
   ],
   "source": [
    "#evalution + visuallisation of regression...\n",
    "def plot_regression_results(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['mae'], label='Train MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Val MAE')\n",
    "    plt.legend()\n",
    "    plt.title('Mean Absolute Error')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_regression_results(history_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[0;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m cnn_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_val\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_val[:, :\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), y_pred\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_val[:, :\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), y_pred\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = cnn_model.predict(X_val)\n",
    "print(classification_report(y_val[:, :2].argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "print(confusion_matrix(y_val[:, :2].argmax(axis=1), y_pred.argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m regression_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_val\u001b[49m)\n\u001b[1;32m      4\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_val[:, \u001b[38;5;241m2\u001b[39m], y_pred))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = regression_model.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val[:, 2], y_pred))\n",
    "print(f\"RMSE: {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory_cnn\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history_cnn\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history_cnn.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_cnn.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"CNN Classification Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
