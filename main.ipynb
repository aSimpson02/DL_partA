{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\Users\\islas\\OneDrive\\Documents\\GitHub\\deep_learning_proj\\.conda\\Lib\\site-packages\\keras\\api\\preprocessing\\image\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (c:\\Users\\islas\\OneDrive\\Documents\\GitHub\\deep_learning_proj\\.conda\\Lib\\site-packages\\keras\\api\\preprocessing\\image\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#Library Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Labels...\n",
      "Loaded 2016 labels.\n",
      "Loading Images...\n",
      "Loaded 2016 images.\n",
      "Parsing Labels...\n"
     ]
    }
   ],
   "source": [
    "#paths...\n",
    "BASE = \"Database\"\n",
    "IMAGES_PATH = os.path.join(BASE, \"Image\")\n",
    "LABELS_PATH = os.path.join(BASE, \"label.txt\")\n",
    "\n",
    "\n",
    "#labels...\n",
    "def load_labels(labels_path):\n",
    "    with open(labels_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    labels = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()  \n",
    "        if len(parts) >= 3:  \n",
    "            try:\n",
    "                pose = float(parts[1]) \n",
    "                depth = float(parts[2])  \n",
    "                labels.append([pose, depth])  \n",
    "            except ValueError:\n",
    "                print(f\"Skipping line due to ValueError: {line}\")  \n",
    "        else:\n",
    "            print(f\"Skipping line due to incorrect format: {line}\") \n",
    "    print(f\"Loaded {len(labels)} labels.\") \n",
    "    return labels\n",
    "\n",
    "\n",
    "#images...\n",
    "def load_images(images_path):\n",
    "    image_paths = []\n",
    "    images = []\n",
    "    for filename in os.listdir(images_path):\n",
    "        if filename.endswith(\".jpeg\") or filename.endswith(\".jpg\"):  \n",
    "            image_paths.append(os.path.join(images_path, filename))\n",
    "            img = cv2.imread(os.path.join(images_path, filename))\n",
    "            if img is not None:\n",
    "                images.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  \n",
    "    print(f\"Loaded {len(images)} images.\")  \n",
    "    return np.array(images), image_paths\n",
    "\n",
    "\n",
    "#data vis\n",
    "def plot_label_distribution(labels_df):\n",
    "    if labels_df.empty:\n",
    "        print(\"No data available for plotting.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(labels_df[\"Pitch\"], bins=20, alpha=0.7, label=\"Pitch\")\n",
    "    plt.hist(labels_df[\"Roll\"], bins=20, alpha=0.7, label=\"Roll\")\n",
    "    plt.hist(labels_df[\"Depth\"], bins=20, alpha=0.7, label=\"Depth\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Label Distributions\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_samples(images, labels_df, sample_size=5):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sample_indices = np.random.choice(len(images), size=sample_size, replace=False)\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        plt.subplot(1, sample_size, i+1)\n",
    "        plt.imshow(images[idx])\n",
    "        plt.title(f\"Image {labels_df.iloc[idx]['Image']}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Load data\n",
    "print(\"Loading Labels...\")\n",
    "labels = load_labels(LABELS_PATH)\n",
    "\n",
    "print(\"Loading Images...\")\n",
    "images, image_paths = load_images(IMAGES_PATH)\n",
    "\n",
    "\n",
    "if images.size == 0 or not labels:\n",
    "    raise ValueError(\"No data loaded. Ensure the dataset paths are correct.\")\n",
    "\n",
    "#parsing labels...\n",
    "print(\"Parsing Labels...\")\n",
    "labels = np.array(labels, dtype=np.float32)\n",
    "y_pose = labels[:, 0]  \n",
    "depth_labels = labels[:, 1]  \n",
    "\n",
    "#normalise\n",
    "X_images = images / 255.0\n",
    "\n",
    "\n",
    "y_labels_combined = np.stack((y_pose, depth_labels), axis=1)\n",
    "\n",
    "#splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_images, y_labels_combined, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (0,)\n",
      "Labels shape: (0, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation...\n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN classification...\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "def build_cnn(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "cnn_model = build_cnn((224, 224, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 23\u001b[0m vgg_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_vgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m, in \u001b[0;36mbuild_vgg\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_vgg\u001b[39m(input_shape):\n\u001b[1;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m([\n\u001b[0;32m      3\u001b[0m         Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39minput_shape),\n\u001b[0;32m      4\u001b[0m         Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      5\u001b[0m         MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m         Conv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      8\u001b[0m         Conv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      9\u001b[0m         MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m         Conv2D(\u001b[38;5;241m256\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     12\u001b[0m         Conv2D(\u001b[38;5;241m256\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     13\u001b[0m         MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m         Flatten(),\n\u001b[0;32m     16\u001b[0m         Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     17\u001b[0m         Dropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m     18\u001b[0m         Dense(\u001b[38;5;241m2\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Classification\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     ])\n\u001b[0;32m     20\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "def build_vgg(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax')  \n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "vgg_model = build_vgg((224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Add, Input\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresidual_block\u001b[39m(x, filters):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Add, Input\n",
    "from keras.models import Model\n",
    "\n",
    "def residual_block(x, filters):\n",
    "    shortcut = x\n",
    "    x = Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Add()([x, shortcut])  # Skip connection\n",
    "    return x\n",
    "\n",
    "def build_resnet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = residual_block(x, 64)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = residual_block(x, 128)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(2, activation='softmax')(x)  \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "resnet_model = build_resnet((224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 15\u001b[0m depth_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_depth_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mbuild_depth_model\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_depth_model\u001b[39m(input_shape):\n\u001b[1;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m([\n\u001b[0;32m      3\u001b[0m         Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39minput_shape),\n\u001b[0;32m      4\u001b[0m         MaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m      5\u001b[0m         Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      6\u001b[0m         MaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m      7\u001b[0m         Flatten(),\n\u001b[0;32m      8\u001b[0m         Dense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      9\u001b[0m         Dropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m     10\u001b[0m         Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Depth regression\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     ])\n\u001b[0;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "#regression model...\n",
    "def build_depth_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='linear')  \n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "depth_model = build_depth_model((224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint\n\u001b[1;32m      4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnn_best_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m history_cnn \u001b[38;5;241m=\u001b[39m cnn_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m----> 7\u001b[0m     augmenter\u001b[38;5;241m.\u001b[39mflow(\u001b[43mX_train\u001b[49m, y_train[:, :\u001b[38;5;241m2\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m),\n\u001b[1;32m      8\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val[:, :\u001b[38;5;241m2\u001b[39m]),\n\u001b[1;32m      9\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m     10\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint]\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#training....\n",
    "cnn_model.fit(\n",
    "    augmenter.flow(X_train, y_train[:, :2], batch_size=32),\n",
    "    validation_data=(X_val, y_val[:, :2]),\n",
    "    epochs=25,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "vgg_model.fit(\n",
    "    augmenter.flow(X_train, y_train[:, :2], batch_size=32),\n",
    "    validation_data=(X_val, y_val[:, :2]),\n",
    "    epochs=25,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "resnet_model.fit(\n",
    "    augmenter.flow(X_train, y_train[:, :2], batch_size=32),\n",
    "    validation_data=(X_val, y_val[:, :2]),\n",
    "    epochs=25,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "depth_model.fit(\n",
    "    augmenter.flow(X_train, y_train[:, 1], batch_size=32), \n",
    "    validation_data=(X_val, y_val[:, 1]),\n",
    "    epochs=25,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training visualisation...\n",
    "def plot_training(history):\n",
    "    if history is None:\n",
    "        print(\"No training history available to plot.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_regression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 18\u001b[0m plot_regression_results(\u001b[43mhistory_regression\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_regression' is not defined"
     ]
    }
   ],
   "source": [
    "#evalution + visuallisation of regression...\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_classification_model(model, X_test, y_test, labels):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=labels))\n",
    "    \n",
    "    plot_confusion_matrix(y_true_classes, y_pred_classes, labels)\n",
    "\n",
    "labels = [\"Pose 0\", \"Pose 1\"]\n",
    "evaluate_classification_model(cnn_model, X_test, y_test[:, :2], labels)\n",
    "evaluate_classification_model(vgg_model, X_test, y_test[:, :2], labels)\n",
    "evaluate_classification_model(resnet_model, X_test, y_test[:, :2], labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_regression_model\u001b[39m(model, X_test, y_test):\n\u001b[0;32m      4\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_regression_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.3f}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.xlabel(\"True Depth\")\n",
    "    plt.ylabel(\"Predicted Depth\")\n",
    "    plt.title(\"True vs Predicted Depth\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "evaluate_regression_model(depth_model, X_test, y_test[:, 1])  # Use depth label (2nd column)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m regression_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_val\u001b[49m)\n\u001b[1;32m      4\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_val[:, \u001b[38;5;241m2\u001b[39m], y_pred))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_training_metrics(history, metric, val_metric, title, ylabel):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history.history[metric], label=f'Train {ylabel}')\n",
    "    plt.plot(history.history[val_metric], label=f'Val {ylabel}')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_classification_training(history):\n",
    "    plot_training_metrics(history, 'accuracy', 'val_accuracy', 'Accuracy Over Epochs', 'Accuracy')\n",
    "    plot_training_metrics(history, 'loss', 'val_loss', 'Loss Over Epochs', 'Loss')\n",
    "\n",
    "def visualize_regression_training(history):\n",
    "    plot_training_metrics(history, 'mae', 'val_mae', 'Mean Absolute Error Over Epochs', 'MAE')\n",
    "    plot_training_metrics(history, 'loss', 'val_loss', 'Loss Over Epochs', 'Loss')\n",
    "\n",
    "\n",
    "visualize_classification_training(history_cnn)\n",
    "visualize_classification_training(history_vgg)\n",
    "visualize_classification_training(history_resnet)\n",
    "\n",
    "visualize_regression_training(history_regression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m     evaluate_regression_model(depth_model, X_test, y_test[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     18\u001b[0m     visualize_regression_training(regression_history)\n\u001b[0;32m     21\u001b[0m evaluate_all_models(\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mhistory_cnn\u001b[49m, history_vgg, history_resnet, history_regression,\n\u001b[0;32m     23\u001b[0m     cnn_model, vgg_model, resnet_model, depth_model,\n\u001b[0;32m     24\u001b[0m     X_test, y_test, labels\n\u001b[0;32m     25\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_all_models(cnn_history, vgg_history, resnet_history, regression_history, \n",
    "                        cnn_model, vgg_model, resnet_model, depth_model, \n",
    "                        X_test, y_test, labels):\n",
    "    print(\"\\n=== CNN Model Evaluation ===\")\n",
    "    evaluate_classification_model(cnn_model, X_test, y_test[:, :2], labels)\n",
    "    visualize_classification_training(cnn_history)\n",
    "    \n",
    "    print(\"\\n=== VGG Model Evaluation ===\")\n",
    "    evaluate_classification_model(vgg_model, X_test, y_test[:, :2], labels)\n",
    "    visualize_classification_training(vgg_history)\n",
    "    \n",
    "    print(\"\\n=== ResNet Model Evaluation ===\")\n",
    "    evaluate_classification_model(resnet_model, X_test, y_test[:, :2], labels)\n",
    "    visualize_classification_training(resnet_history)\n",
    "    \n",
    "    print(\"\\n=== Depth Estimation Model Evaluation ===\")\n",
    "    evaluate_regression_model(depth_model, X_test, y_test[:, 1])\n",
    "    visualize_regression_training(regression_history)\n",
    "\n",
    "\n",
    "evaluate_all_models(\n",
    "    history_cnn, history_vgg, history_resnet, history_regression,\n",
    "    cnn_model, vgg_model, resnet_model, depth_model,\n",
    "    X_test, y_test, labels\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
